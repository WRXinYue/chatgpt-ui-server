import streamlit as st
import openai
import pandas as pd
import os
from tqdm import tqdm
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.chains.question_answering import load_qa_chain
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.llms import OpenAI
# import my_key = ""
my_key = "sk-peYuSGE12SKtWtDH9hxx9ZztJv4Fn4ADDKO5AjVmLOI7CNgw"

# è®¾ç½®é¡µé¢å®½åº¦ä¸ºè¾ƒå®½çš„å¸ƒå±€
st.set_page_config(layout="wide")

# OPENAI_API_BASE = "https://api.chatanywhere.com.cn/v1"

openai.api_base = "https://api.chatanywhere.com.cn/v1"

default_api_url = openai.api_base
print("Default API URL:", default_api_url)
# Set the environment variable OPENAI_API_BASE
# os.environ["OPENAI_API_BASE"] = OPENAI_API_BASE

def analyze_resume(jd, resume, options):
    """
    é€šè¿‡å¯¹è¾“å…¥çš„ç®€å†è¿›è¡Œç»¼åˆåˆ†æï¼Œè¯„ä¼°å€™é€‰äººä¸ç»™å®šèŒä½çš„åŒ¹é…ç¨‹åº¦ï¼Œå¹¶è¿”å›æ¦‚è¦å’Œå¾—åˆ†ã€‚

    Args:
        jd (str): èŒä½æè¿°,èŒä½è¦æ±‚
        resume (str): å€™é€‰äººç®€å†ã€‚
        options (dict): åˆ†æé€‰é¡¹ï¼Œä¾‹å¦‚è¿‡æ»¤æ¡ä»¶æˆ–å…¶ä»–è®¾ç½®ã€‚

    Returns:
        DataFrame: åŒ…å«ç®€å†ç»¼åˆæ¦‚è¦å’ŒåŒ¹é…å¾—åˆ†çš„ DataFrameã€‚
    """

    # è¿›è¡Œç®€å†åˆ†æ
    df = analyze_str(resume, options)

    # è¿›è¡Œæ•°æ®å¤„ç†ï¼šå¦‚æœæ•°æ®ç±»å‹ä¸ºåˆ—è¡¨ï¼Œåˆ™å°†è½¬æ¢ä¸ºä»¥é€—å·åˆ†å‰²çš„å­—ç¬¦ä¸²ï¼›å¦åˆ™ä¸å˜
    df_string = df.applymap(lambda x: ', '.join(x) if isinstance(x, list) else x).to_string(index=False)
    st.write("OpenAIç»¼åˆåˆ†æ..")

    # æ„é€ ä¸€ä¸ªæ¦‚è¦é—®é¢˜å­—ç¬¦ä¸²ï¼Œå†…å®¹åŒ…æ‹¬èŒä½è¦æ±‚å’Œç®€å†æ¦‚è¦ã€‚ç„¶åè°ƒç”¨ ask_openAI å‡½æ•°å‘ OpenAI è¯·æ±‚æ¦‚è¦ä¿¡æ¯ã€‚
    summary_question = f"èŒä½è¦æ±‚æ˜¯ï¼š{{{jd}}}" + f"ç®€å†æ¦‚è¦æ˜¯ï¼š{{{df_string}}}" + "ï¼Œè¯·ç›´æ¥è¿”å›è¯¥åº”è˜å²—ä½å€™é€‰äººåŒ¹é…åº¦æ¦‚è¦ï¼ˆæ§åˆ¶åœ¨200å­—ä»¥å†…ï¼‰;'"
    summary = ask_openAI(summary_question)

    # å°†æ¦‚è¦ä¿¡æ¯æ·»åŠ åˆ° df DataFrame ä¸­
    df.loc[len(df)] = ['ç»¼åˆæ¦‚è¦', summary]

    # è®¾ç½®é¢å¤–çš„æ‰“åˆ†è¦æ±‚è¯´æ˜
    extra_info = "æ‰“åˆ†è¦æ±‚ï¼šå›½å†…top10å¤§å­¦+3åˆ†ï¼Œ985å¤§å­¦+2åˆ†ï¼Œ211å¤§å­¦+1åˆ†ï¼Œå¤´éƒ¨ä¼ä¸šç»å†+2åˆ†ï¼ŒçŸ¥åä¼ä¸š+1åˆ†ï¼Œæµ·å¤–èƒŒæ™¯+3åˆ†ï¼Œå¤–ä¼èƒŒæ™¯+1åˆ†ã€‚ "

    # æ„å»ºä¸€ä¸ªè¯„åˆ†é—®é¢˜å­—ç¬¦ä¸²ï¼Œå†…å®¹åŒ…æ‹¬èŒä½è¦æ±‚ã€ç®€å†æ¦‚è¦ä»¥åŠæ‰“åˆ†è¦æ±‚è¯´æ˜ã€‚ç„¶åè°ƒç”¨ ask_openAI å‡½æ•°å‘OpenAIè¯·æ±‚å€™é€‰äººçš„åŒ¹é…åˆ†æ•°
    score_question = f"èŒä½è¦æ±‚æ˜¯ï¼š{{{jd}}}" + f"ç®€å†æ¦‚è¦æ˜¯ï¼š{{{df.to_string(index=False)}}}" + \
                     "ï¼Œè¯·ç›´æ¥è¿”å›è¯¥åº”è˜å²—ä½å€™é€‰äººçš„åŒ¹é…åˆ†æ•°ï¼ˆ0-100ï¼‰ï¼Œè¯·ç²¾ç¡®æ‰“åˆ†ä»¥æ–¹ä¾¿å…¶ä»–å€™é€‰äººå¯¹æ¯”æ’åºï¼Œ'" + extra_info
    score = ask_openAI(score_question)

    # å°†åŒ¹é…å¾—åˆ†æ·»åŠ åˆ° df DataFrame ä¸­
    df.loc[len(df)] = ['åŒ¹é…å¾—åˆ†', score]
    return df

def ask_openAI(question):
    # ä½¿ç”¨OpenAI APIè·å–ç­”æ¡ˆ
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=question,
        max_tokens=400,
        n=1,
        stop=None,
        temperature=0,
    )
    return response.choices[0].text.strip()

def analyze_str(resume, options):
    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬åˆ‡å‰²å™¨å¯¹è±¡
    text_splitter = CharacterTextSplitter(
        separator="\n",         # æ¢è¡Œç¬¦
        chunk_size=600,         # å—å¤§å°
        chunk_overlap=100,      # å—é‡å 
        length_function=len     # é•¿åº¦
    )
    chunks = text_splitter.split_text(resume)

    embeddings = OpenAIEmbeddings(openai_api_key=my_key)
    knowledge_base = FAISS.from_texts(chunks, embeddings)

    df_data = [{'option': option, 'value': []} for option in options]
    st.write("ä¿¡æ¯æŠ“å–")

    # åˆ›å»ºè¿›åº¦æ¡å’Œç©ºå…ƒç´ 
    progress_bar = st.progress(0)
    option_status = st.empty()

    for i, option in tqdm(enumerate(options), desc="ä¿¡æ¯æŠ“å–ä¸­", unit="é€‰é¡¹", ncols=100):
        question = f"è¿™ä¸ªåº”è˜è€…çš„{option}æ˜¯ä»€ä¹ˆï¼Œè¯·ç²¾ç®€è¿”å›ç­”æ¡ˆï¼Œæœ€å¤šä¸è¶…è¿‡250å­—ï¼Œå¦‚æœæŸ¥æ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å›'æœªæä¾›'"
        docs = knowledge_base.similarity_search(question)

        # åˆ›å»ºOpenAIå¯¹è±¡
        llm = OpenAI(openai_api_key=my_key, temperature=0.3, model_name="text-davinci-003", max_tokens="2000")
        chain = load_qa_chain(llm, chain_type="stuff")
        response = chain.run(input_documents=docs, question=question )
        df_data[i]['value'] = response
        option_status.text(f"æ­£åœ¨æŸ¥æ‰¾ä¿¡æ¯ï¼š{option}")

        # æ›´æ–°è¿›åº¦æ¡
        progress = (i + 1) / len(options)
        progress_bar.progress(progress)

    df = pd.DataFrame(df_data)
    st.success("ç®€å†è¦ç´ å·²è·å–")
    return df

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.title("ğŸš€ GPTæ‹›è˜åˆ†ææœºå™¨äºº")
st.subheader("ğŸª¢ Langchain + ğŸ OpenAI")

# è®¾ç½®é»˜è®¤çš„JDå’Œç®€å†ä¿¡æ¯
default_jd = "ä¸šåŠ¡æ•°æ®åˆ†æå¸ˆJD å²—ä½èŒè´£ï¼š..."
default_resume = "åº”è˜ç®€å† ä¸ªäººä¿¡æ¯ï¼š..."

# è¾“å…¥JDä¿¡æ¯
jd_text = st.text_area("ã€å²—ä½ä¿¡æ¯ã€‘", height=100, value=default_jd)

# è¾“å…¥ç®€å†ä¿¡æ¯
resume_text = st.text_area("ã€åº”è˜ç®€å†ã€‘", height=100, value=default_resume)

# å‚æ•°è¾“å…¥
options = ["å§“å", "è”ç³»å·ç ", "æ€§åˆ«", "å¹´é¾„", "å·¥ä½œå¹´æ•°ï¼ˆæ•°å­—ï¼‰", "æœ€é«˜å­¦å†", "æœ¬ç§‘å­¦æ ¡åç§°", "ç¡•å£«å­¦æ ¡åç§°", "æ˜¯å¦åœ¨èŒ", "å½“å‰èŒåŠ¡", "å†å²ä»»èŒå…¬å¸åˆ—è¡¨", "æŠ€æœ¯èƒ½åŠ›", "ç»éªŒç¨‹åº¦", "ç®¡ç†èƒ½åŠ›"]
selected_options = st.multiselect("è¯·é€‰æ‹©é€‰é¡¹", options, default=options)

# åˆ†ææŒ‰é’®
if st.button("å¼€å§‹åˆ†æ"):
    df = analyze_resume(jd_text, resume_text, selected_options)
    st.subheader("ç»¼åˆåŒ¹é…å¾—åˆ†ï¼š"+ df.loc[df['option'] == 'åŒ¹é…å¾—åˆ†', 'value'].values[0])
    st.subheader("ç»†é¡¹å±•ç¤ºï¼š")
    st.table(df)